import streamlit as st
import pandas as pd
import geopandas as gpd
from scrape_bwf_ranking import scrape_bwf_ranking  # å¼•å…¥ç¬¬ä¸€æ¬¡çˆ¬èŸ²çš„å‡½æ•¸
from scrape_bwf_ranking_by_date import scrape_bwf_ranking_by_date  # å¼•å…¥ç¬¬äºŒæ¬¡çˆ¬èŸ²çš„å‡½æ•¸
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns
import leafmap.foliumap as leafmap
from matplotlib.colors import Normalize

from streamlit_folium import st_folium
import folium



# è¨­å®šé é¢é…ç½®ç‚ºå¯¬å±æ¨¡å¼
st.set_page_config(page_title="Men's Singles", layout="wide", page_icon=":ğŸ¸")

# è¨­å®šé é¢æ¨™é¡Œ
st.title("Men's Singles ç”·å­å–®æ‰“")

row0_1,XX, row0_2 = st.columns((3,1, 4))
with row0_1:
    st.write(
        """
        ##  
        æ­¤é é¢æä¾›å–®ä¸€é¸æ‰‹çš„æœå°‹\n
        å…ˆé¸æ“‡é …ç›®ã€å†è¼¸å…¥é¸æ‰‹å
        ##
        """
    )
with row0_2:
    st.write(
        """
        ##  
        æ³¨æ„ï¼Œè‹¥æ²’æœ‰è¦æ¯”è¼ƒå…©å€‹æ™‚é–“ï¼Œå‰‡å³å´æ—¥æœŸè«‹ä¿ç•™ç©ºç™½(è‹¥èª¤è§¸ï¼Œæ‹‰åˆ°æœ€ä¸Šç‚ºç©ºç™½)\n
        è‹¥é¸æ“‡ï¼Œé é¢æœƒé¡¯ç¤ºå·¦å³å…©å€‹æ™‚é–“çš„è³‡æ–™ï¼Œä¸¦ä¸”åœ¨åº•ä¸‹é¡¯ç¤ºå…©å€‹åœ–å° \n
        ç•¶å·¦å´åœ–å°ç§»å‹•è¦–è§’ï¼Œå³å´åœ–å°ä¹Ÿæœƒè·Ÿé€²(ä½†è‹¥ç§»å‹•å³å´ï¼Œå·¦å´ä¸¦ä¸æœƒè·Ÿè‘—æ”¹è®Š)\n
        ç„¶è€Œç”±æ–¼æŠ€è¡“åŠ›çš„é™åˆ¶ï¼Œåªè¦æœ‰å°å·¦å´åœ–å°é€²è¡Œæ“ä½œ(å¦‚é»é¸ã€ç§»å‹•)\n
        æ•´å€‹é é¢éƒ½æœƒé€²å…¥é‡runçš„ç‹€æ…‹ï¼Œåœ–å°æœƒæš«æ™‚æš—æ‰ï¼Œä½†é‚„æ˜¯å¯æ“ä½œç‹€æ…‹\n
        è‹¥ä¸å–œæ­¡å¿½äº®å¿½æš—çš„é é¢å‘ˆç¾ï¼Œå¯æ–¼ä¸‹æ–¹ "æ˜¯å¦å·¦å³åœ–å°è¯å‹•"é¸æ“‡"å¦"
        """
    )
    user_choice = st.radio("æ˜¯å¦å·¦å³åœ–å°è¯å‹•ï¼š", ("æ˜¯", "å¦"))
    st.write(
        """
        ##  
        """
    )

# ç”¨ä¾†é¡¯ç¤ºè¡¨æ ¼çš„å€åŸŸ
table_area = st.container()

# è¡¨æ ¼çš„å·¦å³åˆ†å€
row1_1, row1_2 = table_area.columns((1, 1))
row2_1, row2_2 = table_area.columns((1, 1))
row3_1, row3_2 = table_area.columns((1, 1))

# æª¢æŸ¥æ˜¯å¦å·²ç¶“å­˜å„²éç¬¬ä¸€æ¬¡çˆ¬èŸ²çš„è³‡æ–™
if "df_initial" not in st.session_state:  # åªæœ‰åœ¨ç¬¬ä¸€æ¬¡çˆ¬èŸ²æœªå®Œæˆæ™‚æ‰æœƒåŸ·è¡Œ
    try:
        url = "https://bwf.tournamentsoftware.com/ranking/category.aspx?id=43595&category=473&C473FOC=&p=1&ps=100"

        # å‘¼å«ç¬¬ä¸€æ¬¡çˆ¬èŸ²ï¼Œç²å–æ’åè³‡æ–™ä¸¦æŠ“å–æ—¥æœŸ-IDå°æ‡‰å­—å…¸
        df_initial, date_id_dict,new_date = scrape_bwf_ranking(url)

        # å„²å­˜ç¬¬ä¸€æ¬¡çˆ¬èŸ²çµæœåˆ° session_state ä¸­
        df_initial.set_index("Rank", inplace=True)
        st.session_state.df_initial = df_initial
        st.session_state.date_id_dict = date_id_dict  # å„²å­˜æ—¥æœŸ-IDå°æ‡‰å­—å…¸
        st.session_state.first_scrape_done = True  # è¨­å®šæ¨™è¨˜ï¼Œè¡¨ç¤ºç¬¬ä¸€æ¬¡çˆ¬èŸ²å·²ç¶“å®Œæˆ
        st.session_state.new_date=new_date # å„²å­˜æœ€æ–°æ—¥æœŸ
    except Exception as e:
        st.error(f"Error occurred: {e}")

if "date_id_dict" in st.session_state:
    date_id_dict = st.session_state.date_id_dict

##################







# ä½¿ç”¨ selectbox1 è®“ä½¿ç”¨è€…é¸æ“‡é …ç›®
options = ["ç”·å­å–®æ‰“","ç”·å­é›™æ‰“","å¥³å­å–®æ‰“","å¥³å­é›™æ‰“","æ··åˆå–®æ‰“",]
index = options[1]

options = list(("ç”·å­å–®æ‰“","ç”·å­é›™æ‰“","å¥³å­å–®æ‰“","å¥³å­é›™æ‰“","æ··åˆå–®æ‰“"))
index = options.index(st.session_state.new_date)

with row2_1:
    selected_date1 = st.selectbox(
        "é¸æ“‡æ¬²æŸ¥è©¢çš„æ—¥æœŸ (é è¨­æœ€æ–°æ—¥æœŸ)",
        options,
        index=index,
        key="selectbox_date1",  # æ·»åŠ å”¯ä¸€çš„ key
    )
# å¦‚æœé¸æ“‡äº†æ—¥æœŸ
if selected_date1:
    try:
        selected_id1 = date_id_dict[selected_date1]
        df_selected1 = scrape_bwf_ranking_by_date(selected_id1)
        df_selected1.set_index("Rank", inplace=True)

        # é¡¯ç¤ºé¸æ“‡æ—¥æœŸçš„æ’åè³‡æ–™æ–¼ row1_1
        with row1_1:
            st.write(f"ä¸‹è¡¨ç‚º {selected_date1}  æ™‚ ç”·å­å–®æ‰“æ’åè³‡æ–™")
            st.write(df_selected1)
    except Exception as e:
        st.error(f"Error occurred while fetching data for {selected_date1}: {e}")

